{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Gaussian process](../papers/Gaussian_process.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\bracket}[1]{\\left\\langle{#1}\\right\\rangle}$\n",
    "$\\newcommand{\\intd}[2]{\\int {#2} {\\rm d}{#1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定定义在 ${x}$ 上 的两个函数， $m(x)$ 和 $k(x, x^\\prime)$，其中 $k(x, x^\\prime)$ 满足“正定”条件，则可以定义一个“随机变量场” $f(x)$, 这个随机变量场，满足:\n",
    "\n",
    "$$\\bracket{f(x)} = m(x)$$\n",
    "$$\\bracket{(f(x)-m(x))(f(x^\\prime) - m(x^\\prime))} = k(x, x^\\prime)$$\n",
    "\n",
    "$m(x)$, $k(x, x^\\prime)$ 被称为prior均值函数 和 方差函数\n",
    "\n",
    "所有满足上述条件的“随机变量场” $f$ 称为一个“Gaussian process”， 记为： $f\\sim\\mathcal{GP}(m, k)$\n",
    "\n",
    "当采样一组数据 $D\\equiv\\{x_i, y_i\\}$ （$y_i$ 是“随机变量场” $f$ 在 $x_i$ 处的一次观测值）, 则，\n",
    "\n",
    "$f$ 的 posterior 分布，记为 $f|D\\sim \\mathcal{GP}(m_D, k_D)$, 可以证明：\n",
    "\n",
    "$$m_D(x) = m(x) + \\begin{bmatrix}k(x_1, x)&\\cdots&k(x_N, x)\\end{bmatrix}\\Sigma^{-1}\\begin{bmatrix}y_1-m(x_1)\\\\\\vdots\\\\y_N-m(x_N)\\end{bmatrix}$$\n",
    "\n",
    "$$k_D(x,x^\\prime) = k(x,x^\\prime) - \\begin{bmatrix}k(x_1, x)&\\cdots&k(x_N, x)\\end{bmatrix}\\Sigma^{-1}\\begin{bmatrix}k(x_1-x^\\prime)\\\\\\vdots\\\\k(x_N-x^\\prime)\\end{bmatrix}$$\n",
    "\n",
    "其中 $$\\Sigma \\equiv \\begin{bmatrix}\n",
    "k(x_1, x_1)&\\cdots& k(x_1, x_N)\\\\\\vdots&\\ddots&\\vdots\\\\k(x_N, x_1)&\\cdots&k(x_N,x_N)\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归问题， 给定$x$ 求 $\\braket{y}$：\n",
    "\n",
    "$$\\braket{y}\\equiv\\intd{y}{y p(y|x)}$$\n",
    "\n",
    "$$p(y|x) \\equiv {p(y,x)\\over{p(x)}} = {\\sum\\limits_{\\theta}p(y, x,\\theta) \\over  \\sum\\limits_{y,\\theta}p(y, x,\\theta) } = {  \\sum\\limits_{\\theta}p(y|x,\\theta) p(x,\\theta)\\over \\sum\\limits_{\\theta}p(x,\\theta)}$$\n",
    "\n",
    "约定 $x,\\theta$ 独立，即 $p(x,\\theta)\\equiv p(x)p(\\theta)$ 则：\n",
    "\n",
    "$$p(y|x) = { p(x)\\sum\\limits_{\\theta}p(y|x,\\theta) p(\\theta) \\over p(x)\\sum\\limits_{\\theta}p(\\theta) } = \\sum\\limits_{\\theta}p(y|x,\\theta) p(\\theta) \\rightarrow \\intd{\\theta}{p(y|x,\\theta) p(\\theta)}$$\n",
    "\n",
    "因此：\n",
    "\n",
    "$$\\braket{y}\\equiv\\intd{y}{y p(y|x)} =\\intd{\\theta}{\\intd{y}{y p(y|x,\\theta) p(\\theta)}} $$\n",
    "\n",
    "鞍点近似，假设 $p(\\theta) \\approx\\delta\\left(\\theta -\\theta^*\\right)$, 则：\n",
    "\n",
    "$$\\braket{y}\\approx \\intd{y}{y p(y|x,\\theta^*)} \\approx \\intd{y}{y \\hat{p}(y|x,\\theta^*)}  $$\n",
    "\n",
    "其中$\\hat{p}$ 是人为选定的某个具体函数 (隐含了某种观测数据可依据函数进行泛化的 belief)，是 $p$ 的 estimator (因为 $p$ 作为形式上的“真实”概率，是无法提前预知的), $\\theta^*$ 由观测到的采样数据 $\\{(x_i, y_i)\\}$ 来决定：\n",
    "\n",
    "$$\\theta^*\\equiv {\\rm argmax}_{\\theta} \\hat{p}(\\theta|\\{x_i\\},\\{y_i\\}) = {\\rm argmax}_{\\theta} \\log \\hat{p}(\\theta|\\{x_i\\},\\{y_i\\}) \n",
    "= {\\rm argmax}_{\\theta} \\log \\hat{p}(\\{y_i\\}|\\{x_i\\},\\theta)\\hat{p}(\\theta) = {\\rm argmax}_{\\theta} \\left\\{\\log \\hat{p}(\\theta) + \\sum_i\\log \\hat{p}(y_i|x_i,\\theta)\\right\\}\n",
    "$$\n",
    "\n",
    "\n",
    "这种决定 $\\theta^*$ 的方式，称为 “MAP” （maximize posterior 最大后验），当 prior distribution $p(\\theta)$ 是常数时，MAP 退化为 MLE（maximize likelihood estimation 最大似然估计）， $p(\\theta)$ 非常数时，它相当于一个正则化项（regularization）。\n",
    "\n",
    "另一种“全贝叶斯”的估算方法是：\n",
    "\n",
    "$$\\braket{y}\\equiv\\intd{y}{y p(y|x)} =\\intd{\\theta}{\\intd{y}{y p(y|x,\\theta) p(\\theta)}}\\approx \n",
    "\\intd{\\theta}{\\intd{y}{y \\hat{p}(y|x,\\theta) \\hat{p}(\\theta|\\{x_i\\},\\{y_i\\})}}\n",
    "$$\n",
    "\n",
    "其中\n",
    "\n",
    "$$\\hat{p}(\\theta|\\{x_i\\},\\{y_i\\}) = {\\hat{p}(\\{y_i\\}|\\{x_i\\},\\theta) \\hat{p}(\\theta|\\{x_i\\})\\over \\hat{p}(\\{y_i\\}|\\{x_i\\})}$$\n",
    "\n",
    "根据 i.i.d （independent identical distribution），以及 $\\theta$ 与 $\\{x_i\\}$ 独立的约定，有：\n",
    "\n",
    "$$\\hat{p}(\\theta|\\{x_i\\},\\{y_i\\}) = {\\hat{p}(\\theta)\\prod\\limits_i\\hat{p}(y_i|x_i,\\theta)\\over\\prod\\limits_i\\hat{p}(y_i|x_i)}\n",
    "={1\\over C}\\hat{p}(\\theta)\\prod\\limits_i\\hat{p}(y_i|x_i,\\theta) \n",
    "$$\n",
    "\n",
    "其中 常数 $C$ 可根据 归一化条件 $\\intd{\\theta}{\\hat{p}(\\theta|\\{x_i\\},\\{y_i\\})}=1$ 来确定 \n",
    "\n",
    "于是“全贝叶斯”的估算公式化为：\n",
    "\n",
    "$$\\braket{y}\\equiv\\intd{y}{y p(y|x)} \\approx \n",
    "{1\\over C}\\intd{\\theta}{\\intd{y}{y \\hat{p}(y|x,\\theta) \\left(\\prod\\limits_i\\hat{p}(y_i|x_i,\\theta) \\right)p(\\theta)} }\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
